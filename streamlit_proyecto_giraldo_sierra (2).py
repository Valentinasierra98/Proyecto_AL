# -*- coding: utf-8 -*-
"""Copia de STREAMLIT_Proyecto_Giraldo_Sierra.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZnayP3lGKq1bUyE14Z4ZFZ8W1kxlWSEv
"""

# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import (classification_report, confusion_matrix,
                           roc_curve, auc, precision_recall_curve,
                           accuracy_score, recall_score, precision_score, f1_score)
from sklearn.calibration import calibration_curve
import io
import joblib
import time
import os
from PIL import Image

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Bank Marketing Predictor Pro",
    page_icon="üè¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Manejo de rutas de archivos
def get_file_path(filename):
    """Construye rutas de archivo seguras para diferentes entornos"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(current_dir, filename)

# Cargar datos con manejo de errores
@st.cache_data
def load_data():
    try:
        df = pd.read_csv(get_file_path('bank.csv'))
        return df.drop_duplicates()
    except Exception as e:
        st.error(f"Error cargando datos: {str(e)}")
        return None

# Preprocesamiento mejorado
def preprocess_data(df):
    try:
        # Codificaci√≥n one-hot con manejo de categor√≠as faltantes
        cat_cols = df.select_dtypes(include=['object']).columns
        df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)

        # Eliminar variables con alta colinealidad
        cor_matrix = df_encoded.corr().abs()
        upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))
        to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.8)]
        df_encoded = df_encoded.drop(columns=to_drop, errors='ignore')

        # Divisi√≥n de datos
        if 'deposit_yes' not in df_encoded.columns:
            raise KeyError("Columna target 'deposit_yes' no encontrada")

        y = df_encoded['deposit_yes'].astype(int)
        X = df_encoded.drop('deposit_yes', axis=1)

        # Validaci√≥n de datos
        if len(X) == 0 or len(y) == 0:
            raise ValueError("Datos vac√≠os despu√©s del preprocesamiento")

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # Escalado con validaci√≥n
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        return X_train_scaled, X_test_scaled, y_train, y_test, scaler, X.columns.tolist()

    except Exception as e:
        st.error(f"Error en preprocesamiento: {str(e)}")
        return None, None, None, None, None, None

# Modelo con validaci√≥n
def train_winner_model(X_train, y_train):
    try:
        model = SVC(
            C=0.71,
            kernel='poly',
            class_weight='balanced',
            probability=True,
            random_state=42
        )
        model.fit(X_train, y_train)
        return model
    except Exception as e:
        st.error(f"Error entrenando modelo: {str(e)}")
        return None

# Predicci√≥n con manejo robusto
def predict_new_data(model, scaler, input_data, feature_names):
    try:
        input_df = pd.DataFrame([input_data])

        # One-hot encoding din√°mico
        cat_cols = ['job', 'marital', 'education', 'default', 'housing',
                   'loan', 'contact', 'month', 'poutcome']

        for col in cat_cols:
            if col in input_df.columns:
                input_df = pd.get_dummies(input_df, columns=[col], drop_first=True)

        # Asegurar columnas requeridas
        missing_cols = set(feature_names) - set(input_df.columns)
        for col in missing_cols:
            input_df[col] = 0

        # Validaci√≥n de caracter√≠sticas
        if not all(col in input_df.columns for col in feature_names):
            raise ValueError("Faltan caracter√≠sticas requeridas")

        input_df = input_df[feature_names]
        input_scaled = scaler.transform(input_df)

        prediction = model.predict(input_scaled)
        proba = model.predict_proba(input_scaled)[0][1]

        return prediction[0], proba

    except Exception as e:
        st.error(f"Error en predicci√≥n: {str(e)}")
        return None, None

# Interfaz de usuario mejorada
def main():
    st.title("üè¶ Modelo de Predicci√≥n de Dep√≥sitos Bancarios")
    st.markdown("""
    **Aplicaci√≥n para predecir la aceptaci√≥n de dep√≥sitos a plazo fijo usando Machine Learning**
    """)

    # Carga de datos
    df = load_data()
    if df is None:
        st.warning("No se pudieron cargar los datos. Verifica el archivo 'bank.csv'")
        return

    # Preprocesamiento
    X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_names = preprocess_data(df)
    if X_train_scaled is None:
        return

    # Sidebar
    st.sidebar.header("Men√∫ Principal")
    app_mode = st.sidebar.radio("Seleccione el modo:",
                               ["üìä Informaci√≥n del Modelo",
                                "üîç Evaluaci√≥n del Modelo",
                                "üë§ Predicci√≥n Individual",
                                "üìÇ Predicci√≥n por Lote"])

    # Modos de operaci√≥n
    if app_mode == "üìä Informaci√≥n del Modelo":
        st.header("Informaci√≥n T√©cnica del Modelo")
        with st.expander("üîç Detalles del Modelo"):
            st.markdown("""
            **Modelo:** Support Vector Machine (SVM) con kernel polin√≥mico
            **Par√°metros optimizados:**
            - Regularizaci√≥n (C): 0.71
            - Kernel: Polin√≥mico
            - Balance de clases: Activado
            """)

        with st.expander("üìà Rendimiento Esperado"):
            st.metric("Accuracy", "85% ¬± 2%")
            st.metric("Recall", "88% ¬± 3%")
            st.metric("Precision", "83% ¬± 2%")

        st.subheader("Datos de Entrenamiento")
        st.dataframe(df.head(), use_container_width=True)

    elif app_mode == "üîç Evaluaci√≥n del Modelo":
        st.header("Evaluaci√≥n del Modelo")

        if st.button("üöÄ Entrenar Modelo", type="primary"):
            with st.spinner("Entrenando modelo SVM..."):
                model = train_winner_model(X_train_scaled, y_train)

                if model is not None:
                    y_pred = model.predict(X_test_scaled)
                    y_proba = model.predict_proba(X_test_scaled)[:, 1]

                    # Guardar modelo
                    joblib.dump(model, get_file_path('model.pkl'))
                    joblib.dump(scaler, get_file_path('scaler.pkl'))

                    st.success("Modelo entrenado exitosamente!")

                    # Mostrar resultados en pesta√±as
                    tab1, tab2, tab3 = st.tabs(["üìä M√©tricas", "üìâ Matriz de Confusi√≥n", "üìà Curva ROC"])

                    with tab1:
                        col1, col2 = st.columns(2)
                        col1.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.2%}")
                        col2.metric("F1-Score", f"{f1_score(y_test, y_pred):.2%}")

                        st.dataframe(pd.DataFrame({
                            'M√©trica': ['Precision', 'Recall'],
                            'Valor': [precision_score(y_test, y_pred), recall_score(y_test, y_pred)]
                        }), hide_index=True)

                    with tab2:
                        fig, ax = plt.subplots()
                        sns.heatmap(confusion_matrix(y_test, y_pred),
                                   annot=True, fmt='d', cmap='Blues', ax=ax)
                        st.pyplot(fig)

                    with tab3:
                        fpr, tpr, _ = roc_curve(y_test, y_proba)
                        fig, ax = plt.subplots()
                        ax.plot(fpr, tpr, label=f"AUC = {auc(fpr, tpr):.2f}")
                        ax.plot([0, 1], [0, 1], 'k--')
                        ax.set_xlabel('False Positive Rate')
                        ax.set_ylabel('True Positive Rate')
                        ax.legend()
                        st.pyplot(fig)

    elif app_mode == "üë§ Predicci√≥n Individual":
        st.header("Predicci√≥n para Cliente Individual")

        with st.form("input_form"):
            col1, col2 = st.columns(2)

            with col1:
                age = st.slider("Edad", 18, 100, 30)
                job = st.selectbox("Ocupaci√≥n", df['job'].unique())
                marital = st.selectbox("Estado Civil", df['marital'].unique())
                education = st.selectbox("Educaci√≥n", df['education'].unique())
                balance = st.number_input("Balance (‚Ç¨)", min_value=-5000, max_value=100000, value=0)

            with col2:
                housing = st.radio("Cr√©dito Hipotecario", ['no', 'yes'], horizontal=True)
                loan = st.radio("Pr√©stamo Personal", ['no', 'yes'], horizontal=True)
                contact = st.selectbox("Medio de Contacto", df['contact'].unique())
                duration = st.number_input("Duraci√≥n Contacto (seg)", min_value=0, value=180)
                campaign = st.number_input("N¬∞ Contactos Campa√±a", min_value=1, value=1)

            submitted = st.form_submit_button("Predecir")

            if submitted:
                input_data = {
                    'age': age, 'job': job, 'marital': marital,
                    'education': education, 'balance': balance,
                    'housing': housing, 'loan': loan, 'contact': contact,
                    'duration': duration, 'campaign': campaign
                }

                try:
                    model = joblib.load(get_file_path('model.pkl'))
                    scaler = joblib.load(get_file_path('scaler.pkl'))

                    prediction, proba = predict_new_data(model, scaler, input_data, feature_names)

                    if prediction is not None:
                        st.subheader("Resultado")
                        if prediction == 1:
                            st.success(f"‚úÖ Cliente ACEPTAR√Å dep√≥sito (Probabilidad: {proba:.2%})")
                        else:
                            st.error(f"‚ùå Cliente NO aceptar√° dep√≥sito (Probabilidad: {1-proba:.2%})")

                        # Visualizaci√≥n
                        fig, ax = plt.subplots(figsize=(6, 1))
                        ax.barh([0], [proba], color='green' if prediction == 1 else 'red')
                        ax.set_xlim(0, 1)
                        ax.set_xticks([])
                        ax.set_yticks([])
                        ax.text(0.5, 0, f"{proba:.2%}", ha='center', va='center', color='white')
                        st.pyplot(fig)

                except FileNotFoundError:
                    st.warning("‚ö†Ô∏è Primero debe entrenar el modelo en la pesta√±a de Evaluaci√≥n")

    elif app_mode == "üìÇ Predicci√≥n por Lote":
        st.header("Predicci√≥n para Lote de Clientes")

        uploaded_file = st.file_uploader("Subir archivo CSV", type="csv")

        if uploaded_file is not None:
            try:
                batch_df = pd.read_csv(uploaded_file)
                st.success(f"Datos cargados correctamente ({len(batch_df)} registros)")
                st.dataframe(batch_df.head())

                if st.button("Generar Predicciones", type="primary"):
                    with st.spinner("Procesando..."):
                        try:
                            model = joblib.load(get_file_path('model.pkl'))
                            scaler = joblib.load(get_file_path('scaler.pkl'))

                            # Preprocesamiento del batch
                            batch_encoded = pd.get_dummies(batch_df,
                                                         columns=batch_df.select_dtypes(include=['object']).columns,
                                                         drop_first=True)

                            missing_cols = set(feature_names) - set(batch_encoded.columns)
                            for col in missing_cols:
                                batch_encoded[col] = 0

                            batch_encoded = batch_encoded[feature_names]
                            batch_scaled = scaler.transform(batch_encoded)

                            predictions = model.predict(batch_scaled)
                            probabilities = model.predict_proba(batch_scaled)[:, 1]

                            results_df = batch_df.copy()
                            results_df['Predicci√≥n'] = ['Acepta' if p == 1 else 'Rechaza' for p in predictions]
                            results_df['Probabilidad'] = probabilities

                            st.success("Predicciones completadas!")
                            st.dataframe(results_df.sort_values('Probabilidad', ascending=False))

                            # Exportar resultados
                            csv = results_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                "Descargar Resultados",
                                csv,
                                "resultados_depositos.csv",
                                "text/csv",
                                key='download-csv'
                            )

                        except Exception as e:
                            st.error(f"Error en predicci√≥n: {str(e)}")

            except Exception as e:
                st.error(f"Error leyendo archivo: {str(e)}")

if __name__ == "__main__":
    main()