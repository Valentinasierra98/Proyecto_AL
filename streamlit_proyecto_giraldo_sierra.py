# -*- coding: utf-8 -*-
"""STREAMLIT_Proyecto_Giraldo_Sierra.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wyeTKI98a4KG3ZCEGwiljJK31WbrXrdj

# PROYECTO FINAL
## Curso: Aprendizaje AutomÃ¡tico  
### MaestrÃ­a en Inteligencia Artificial y Ciencia de Datos  

---

## Elaborado por:  
- **Jahir Alberto Giraldo (22500239)**  
- **Valentina Sierra CaÃ±a (22500212)**  

---

# Manual de Usuario - AplicaciÃ³n Modelo de PredicciÃ³n de DepÃ³sitos Bancarios

---

## IntroducciÃ³n

Esta aplicaciÃ³n web permite predecir si un cliente bancario aceptarÃ¡ una oferta de depÃ³sito a plazo fijo, utilizando un modelo de aprendizaje automÃ¡tico basado en Support Vector Classification (SVC). La app estÃ¡ diseÃ±ada para que equipos comerciales y de marketing puedan enfocar sus esfuerzos en clientes con mayor probabilidad de conversiÃ³n.

---

## Requisitos Previos

- Tener acceso a Google Colab o cualquier entorno donde se pueda ejecutar Python.
- Contar con un archivo CSV con datos de clientes (solo para la opciÃ³n de predicciÃ³n por lote).
- ConexiÃ³n a internet para descargar paquetes y ejecutar la app.

---

## Pasos para Ejecutar la AplicaciÃ³n

### 1. Subir Archivo CSV en Google Colab

Para que la aplicaciÃ³n funcione correctamente, es necesario subir un archivo CSV con los datos que se usaron para entrenar el modelo. Este archivo debe contener las caracterÃ­sticas de los clientes y debe llamarse exactamente bank.csv. AsegÃºrate de que el archivo tenga el formato adecuado y que incluya todas las columnas requeridas para que el modelo pueda procesar la informaciÃ³n y realizar predicciones precisas.

### 2. Crear y Ejecutar la AplicaciÃ³n

El cÃ³digo app.py contiene toda la lÃ³gica del modelo y la interfaz web con Streamlit. Para crear y ejecutar la app, sigue estos pasos:

El cÃ³digo crea automÃ¡ticamente el archivo app.py.

Instala las librerÃ­as necesarias (streamlit, pyngrok).

# Uso de la AplicaciÃ³n

Al abrir la app, verÃ¡s el menÃº lateral con varias opciones:

### A. InformaciÃ³n del Modelo
- **QuÃ© es:**  
  DescripciÃ³n del modelo SVM y sus parÃ¡metros.

- **QuÃ© muestra:**  
  Variables mÃ¡s importantes y una vista previa de los datos de entrenamiento.

- **Para quÃ© sirve:**  
  Entender cÃ³mo funciona el modelo y quÃ© datos utiliza.

### B. EvaluaciÃ³n del Modelo
- AquÃ­ puedes entrenar el modelo con los datos disponibles.

- Al entrenar, verÃ¡s mÃ©tricas clave como Accuracy, Precision, Recall y F1-score.

- TambiÃ©n podrÃ¡s observar:  
  - Matriz de confusiÃ³n  
  - Curva ROC (evaluaciÃ³n visual del rendimiento)  
  - Reporte completo de clasificaciÃ³n

- Puedes descargar el reporte en formato CSV para anÃ¡lisis posterior.

### C. PredicciÃ³n Individual
- Formulario para ingresar datos de un cliente especÃ­fico.

- Campos como edad, trabajo, estado civil, balance, duraciÃ³n de llamada, etc.

- Al enviar, la app predice si el cliente aceptarÃ¡ el depÃ³sito y muestra la probabilidad.

- Incluye una barra de progreso visual de la probabilidad.

### D. PredicciÃ³n por Lote
- Puedes subir un archivo CSV con varios registros de clientes.

- La app procesarÃ¡ el archivo y generarÃ¡ predicciones para todos los clientes.

- Muestra una tabla con los resultados y probabilidades.

- Permite descargar un archivo CSV con las predicciones.
"""

# Subir archivo CSV desde la PC en Google Colab
from google.colab import files
uploaded = files.upload()

# Verificar que se haya subido un archivo .csv
import os

csv_filename = None
for fname in uploaded.keys():
    if fname.lower().endswith(".csv"):
        csv_filename = fname
        print(f" Archivo CSV detectado: {csv_filename}")
        break

if not csv_filename:
    raise ValueError(" No se subiÃ³ un archivo CSV vÃ¡lido.")

"""#STREAMLIT CREACIÃ“N DEL APP.PY"""

# Crear archivo app.py con solo el modelo ganador SVM
app_code = '''
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import (classification_report, confusion_matrix,
                           roc_curve, auc, precision_recall_curve,
                           accuracy_score, recall_score, precision_score, f1_score)
from sklearn.calibration import calibration_curve
import io
import joblib
import time
from PIL import Image

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="Bank Marketing Predictor Pro",
    page_icon="ðŸ¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Cargar logo (Pondremos un emoji)
def load_logo():
    # Esto es un placeholder - puedes reemplazarlo con Image.open("tu_logo.png")
    logo = Image.new('RGB', (100, 50), color=(73, 109, 137))
    return logo

logo = load_logo()

# TÃ­tulo de la aplicaciÃ³n con logo
st.image(logo, width=100)
st.title("ðŸ¦ Modelo de PredicciÃ³n de DepÃ³sitos")
st.markdown("""
**Esta aplicaciÃ³n utiliza un modelo de clasificaciÃ³n SVC (Support Vector Classification)
optimizado para predecir si un cliente aceptarÃ¡ una oferta de depÃ³sito a plazo.
El modelo ha sido entrenado con datos reales de campaÃ±as de marketing bancario,
considerando variables como edad, ocupaciÃ³n, historial crediticio y comportamiento en campaÃ±as anteriores.
Al ingresar las caracterÃ­sticas de un cliente, la aplicaciÃ³n estima la probabilidad de aceptaciÃ³n,
ayudando a los equipos comerciales y de marketing a tomar decisiones mÃ¡s informadas
y enfocar sus esfuerzos en clientes con mayor probabilidad de conversiÃ³n.**
""")

# Cargar los datos
@st.cache_data
def load_data():
    df = pd.read_csv('bank.csv')
    df = df.drop_duplicates()
    return df

df = load_data()

# Preprocesamiento
def preprocess_data(df):
    # CodificaciÃ³n one-hot
    cat_cols = df.select_dtypes(include=['object']).columns
    df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)

    # Eliminar variables con alta colinealidad
    cor_matrix = df_encoded.corr().abs()
    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))
    to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.8)]
    df_encoded = df_encoded.drop(columns=to_drop)

    # DivisiÃ³n de datos
    y = df_encoded['deposit_yes'].astype(int)
    X = df_encoded.drop('deposit_yes', axis=1)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Escalado
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, X.columns

# Modelo ganador
def train_winner_model(X_train, y_train):
    model = SVC(
        C=0.71,
        kernel='poly',
        class_weight='balanced',
        probability=True,
        random_state=42
    )
    model.fit(X_train, y_train)
    return model

# FunciÃ³n para predecir nuevos datos
def predict_new_data(model, scaler, input_data, feature_names):
    # Preprocesar los datos de entrada
    input_df = pd.DataFrame([input_data])

    # One-hot encoding para las variables categÃ³ricas
    cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']
    for col in cat_cols:
        if col in input_df.columns:
            input_df = pd.get_dummies(input_df, columns=[col], drop_first=True)

    # Asegurar que tengamos todas las columnas necesarias
    missing_cols = set(feature_names) - set(input_df.columns)
    for col in missing_cols:
        input_df[col] = 0

    # Reordenar columnas
    input_df = input_df[feature_names]

    # Escalar los datos
    input_scaled = scaler.transform(input_df)

    # Predecir
    prediction = model.predict(input_scaled)
    proba = model.predict_proba(input_scaled)[0][1]

    return prediction[0], proba

# Interfaz principal
def main():
    if df is not None:
        X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_names = preprocess_data(df)

        # Sidebar con opciones
        st.sidebar.header("Opciones")
        app_mode = st.sidebar.selectbox("Seleccione el modo",
                                      ["InformaciÃ³n del Modelo", "EvaluaciÃ³n del Modelo", "PredicciÃ³n Individual", "PredicciÃ³n por Lote"])

        if app_mode == "InformaciÃ³n del Modelo":
            st.header("Modelo Predictivo Optimizado de Alta PrecisiÃ³n")
            st.markdown("""
            **Support Vector Machine (SVC) con kernel polinÃ³mico optimizado**

            - **ParÃ¡metros:**
                - C: 0.71 (parÃ¡metro de regularizaciÃ³n)
                - Kernel: polinÃ³mico
                - Balanceo de clases: activado
                - Random state: 42
            - **Rendimiento esperado:**
                - Accuracy: ~0.85
                - Recall: ~0.88
                - Precision: ~0.83
                - F1-score: ~0.85
            """)

            st.subheader("Variables Importantes")
            st.markdown("""
            Las caracterÃ­sticas mÃ¡s importantes para la predicciÃ³n incluyen:
            - DuraciÃ³n de la Ãºltima llamada
            - NÃºmero de contactos en esta campaÃ±a
            - Resultado de campaÃ±as anteriores
            - Edad del cliente
            - Balance en la cuenta
            """)

            st.subheader("Base de Datos")
            st.write("Vista previa de los datos:")
            st.dataframe(df.head())

        elif app_mode == "EvaluaciÃ³n del Modelo":
            st.header("EvaluaciÃ³n del Modelo")

            if st.button("Entrenar y Evaluar Modelo"):
                with st.spinner("Entrenando modelo..."):
                    model = train_winner_model(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                    y_proba = model.predict_proba(X_test_scaled)[:, 1]

                    # Guardar modelo
                    joblib.dump(model, 'bank_marketing_model.pkl')
                    joblib.dump(scaler, 'scaler.pkl')

                    st.success("Modelo entrenado y guardado correctamente!")

                    # Mostrar mÃ©tricas en pestaÃ±as
                    tab1, tab2, tab3, tab4 = st.tabs(["MÃ©tricas", "Matriz de ConfusiÃ³n", "Curva ROC", "Reporte Completo"])

                    with tab1:
                        st.subheader("MÃ©tricas Principales")
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.4f}",
                                  help="ProporciÃ³n de predicciones correctas")
                        col2.metric("Precision", f"{precision_score(y_test, y_pred):.4f}",
                                  help="ProporciÃ³n de verdaderos positivos entre todos los positivos predichos")
                        col3.metric("Recall", f"{recall_score(y_test, y_pred):.4f}",
                                  help="ProporciÃ³n de verdaderos positivos identificados correctamente")
                        col4.metric("F1-score", f"{f1_score(y_test, y_pred):.4f}",
                                  help="Media armÃ³nica de precision y recall")

                    with tab2:
                        st.subheader("Matriz de ConfusiÃ³n")
                        cm = confusion_matrix(y_test, y_pred)
                        fig, ax = plt.subplots(figsize=(6, 4))
                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                                   xticklabels=['No Deposit', 'Deposit'],
                                   yticklabels=['No Deposit', 'Deposit'])
                        ax.set_xlabel('Predicho')
                        ax.set_ylabel('Real')
                        st.pyplot(fig)

                    with tab3:
                        st.subheader("Curva ROC")
                        fpr, tpr, _ = roc_curve(y_test, y_proba)
                        roc_auc = auc(fpr, tpr)
                        fig, ax = plt.subplots(figsize=(8, 6))
                        ax.plot(fpr, tpr, label=f'Ãrea bajo la curva = {roc_auc:.4f}')
                        ax.plot([0, 1], [0, 1], 'k--')
                        ax.set_xlabel('Tasa de Falsos Positivos')
                        ax.set_ylabel('Tasa de Verdaderos Positivos')
                        ax.set_title('Curva ROC')
                        ax.legend(loc="lower right")
                        st.pyplot(fig)

                    with tab4:
                        st.subheader("Reporte de ClasificaciÃ³n")
                        report = classification_report(y_test, y_pred, output_dict=True)
                        report_df = pd.DataFrame(report).transpose()
                        st.dataframe(report_df.style.highlight_max(axis=0))

                        # OpciÃ³n para descargar el reporte
                        csv = report_df.to_csv(index=True).encode('utf-8')
                        st.download_button(
                            "Descargar Reporte como CSV",
                            csv,
                            "model_report.csv",
                            "text/csv",
                            key='download-csv'
                        )

        elif app_mode == "PredicciÃ³n Individual":
            st.header("PredicciÃ³n Individual")
            st.markdown("Complete los datos del cliente para predecir si aceptarÃ¡ el depÃ³sito a plazo.")

            # Formulario para entrada de datos
            with st.form("prediction_form"):
                col1, col2 = st.columns(2)

                with col1:
                    age = st.number_input("Edad", min_value=18, max_value=100, value=30)
                    job = st.selectbox("Trabajo", df['job'].unique())
                    marital = st.selectbox("Estado Civil", df['marital'].unique())
                    education = st.selectbox("EducaciÃ³n", df['education'].unique())
                    default = st.selectbox("Tiene crÃ©dito en default?", ['no', 'yes'])
                    balance = st.number_input("Balance (â‚¬)", value=0)

                with col2:
                    housing = st.selectbox("Tiene crÃ©dito hipotecario?", ['no', 'yes'])
                    loan = st.selectbox("Tiene prÃ©stamo personal?", ['no', 'yes'])
                    contact = st.selectbox("Medio de contacto", df['contact'].unique())
                    day = st.number_input("DÃ­a del mes", min_value=1, max_value=31, value=15)
                    month = st.selectbox("Mes", df['month'].unique())
                    duration = st.number_input("DuraciÃ³n Ãºltimo contacto (seg)", min_value=0, value=180)

                campaign = st.number_input("NÃºmero de contactos en esta campaÃ±a", min_value=1, value=1)
                pdays = st.number_input("DÃ­as desde Ãºltimo contacto", min_value=-1, value=-1)
                previous = st.number_input("NÃºmero de contactos antes de esta campaÃ±a", min_value=0, value=0)
                poutcome = st.selectbox("Resultado de la campaÃ±a anterior", df['poutcome'].unique())

                submitted = st.form_submit_button("Predecir")

                if submitted:
                    input_data = {
                        'age': age,
                        'job': job,
                        'marital': marital,
                        'education': education,
                        'default': default,
                        'balance': balance,
                        'housing': housing,
                        'loan': loan,
                        'contact': contact,
                        'day': day,
                        'month': month,
                        'duration': duration,
                        'campaign': campaign,
                        'pdays': pdays,
                        'previous': previous,
                        'poutcome': poutcome
                    }

                    try:
                        model = joblib.load('bank_marketing_model.pkl')
                        scaler = joblib.load('scaler.pkl')

                        prediction, probability = predict_new_data(model, scaler, input_data, feature_names)

                        st.subheader("Resultado de la PredicciÃ³n")
                        if prediction == 1:
                            st.success(f"El cliente **SÃ** aceptarÃ¡ el depÃ³sito a plazo (probabilidad: {probability:.2%})")
                        else:
                            st.error(f"El cliente **NO** aceptarÃ¡ el depÃ³sito a plazo (probabilidad: {1-probability:.2%})")

                        # Mostrar barra de probabilidad
                        st.progress(probability)
                        st.metric("Probabilidad de aceptaciÃ³n", f"{probability:.2%}")

                    except FileNotFoundError:
                        st.warning("Primero debe entrenar el modelo en la pestaÃ±a 'EvaluaciÃ³n del Modelo'")

        elif app_mode == "PredicciÃ³n por Lote":
            st.header("PredicciÃ³n por Lote")
            st.markdown("Suba un archivo CSV con los datos de los clientes para generar predicciones.")

            uploaded_file = st.file_uploader("Seleccione un archivo CSV", type="csv")

            if uploaded_file is not None:
                try:
                    batch_df = pd.read_csv(uploaded_file)
                    st.write("Vista previa de los datos cargados:", batch_df.head())

                    if st.button("Generar Predicciones"):
                        with st.spinner("Procesando datos..."):
                            # Preprocesar el batch
                            batch_encoded = pd.get_dummies(batch_df,
                                                         columns=batch_df.select_dtypes(include=['object']).columns,
                                                         drop_first=True)

                            # Asegurar que tenemos todas las columnas necesarias
                            missing_cols = set(feature_names) - set(batch_encoded.columns)
                            for col in missing_cols:
                                batch_encoded[col] = 0

                            # Reordenar columnas
                            batch_encoded = batch_encoded[feature_names]

                            # Escalar y predecir
                            scaler = joblib.load('scaler.pkl')
                            model = joblib.load('bank_marketing_model.pkl')

                            batch_scaled = scaler.transform(batch_encoded)
                            predictions = model.predict(batch_scaled)
                            probabilities = model.predict_proba(batch_scaled)[:, 1]

                            # AÃ±adir predicciones al dataframe
                            result_df = batch_df.copy()
                            result_df['PredicciÃ³n'] = ['SÃ­' if p == 1 else 'No' for p in predictions]
                            result_df['Probabilidad'] = probabilities

                            st.success("Predicciones completadas!")
                            st.dataframe(result_df)

                            # OpciÃ³n para descargar resultados
                            csv = result_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                "Descargar Resultados",
                                csv,
                                "predicciones_clientes.csv",
                                "text/csv",
                                key='download-batch-csv'
                            )

                except Exception as e:
                    st.error(f"Error al procesar el archivo: {str(e)}")

if __name__ == "__main__":
    main()
'''
with open('app.py', 'w') as f:
    f.write(app_code)
print("Archivo app.py creado")

!pip install streamlit pyngrok

!streamlit run app.py &>/dev/null&

!pip install streamlit

!streamlit run app.py &>/content/logs.txt &


!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared
!chmod +x cloudflared
!./cloudflared tunnel --url http://localhost:8501